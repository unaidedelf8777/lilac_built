{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset.map()\n",
    "\n",
    "This notebook shows a workflow for using `Dataset.map`.\n",
    "\n",
    "`Dataset.map()` works like a standard map function, creating a new column using a python function that reads the existing rows, with extra API to allow the UI to visualize changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhil/Code/lilac/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import lilac as ll\n",
    "\n",
    "ll.set_project_dir('./data')\n",
    "\n",
    "try:\n",
    "  glue = ll.get_dataset('local', 'glue_ax_map')\n",
    "except Exception as e:\n",
    "  glue = ll.create_dataset(\n",
    "    ll.DatasetConfig(\n",
    "      namespace='local',\n",
    "      name='glue_ax_map',\n",
    "      source=ll.HuggingFaceSource(dataset_name='glue', config_name='ax', sample_size=100),\n",
    "    )\n",
    "  )\n",
    "\n",
    "# ll.start_server()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple `map`: upper case 'premise'\n",
    "\n",
    "The following map will upper case the `premise` field from the dataset. When you have the [Lilac UI](http://localhost:5432) opened in a new tab, you will see the progress as your map is executed.\n",
    "\n",
    "Once it's complete, refresh the UI to see the results.\n",
    "\n",
    "The output of the map is also returned as a generator so you can print it easily. The results of the generator are simply what your map outputed.\n",
    "\n",
    "You can use `select_rows` to merge it with source data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduling task \"6c5b363446bf44b9b84b0321e5d7087f\": \"[local/glue_ax_map][shard 0/1] map \"_upper\" to \"_upper\"\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[local/glue_ax_map][shard 0/1] map \"_upper\" to \"_upper\": 100%|██████████| 1104/1104 [00:00<00:00, 55017.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A RABBI IS AT THIS WEDDING, STANDING RIGHT THERE STANDING BEHIND THAT TREE.\n",
      "\n",
      "Scheduling task \"dee8d22356a2400aba4210667d937bf7\": \"[local/glue_ax_map][shard 0/1] map \"_upper\" to \"premise_upper\"\".\n",
      "Task finished \"6c5b363446bf44b9b84b0321e5d7087f\": \"[local/glue_ax_map][shard 0/1] map \"_upper\" to \"_upper\"\" in 5s.\n",
      "Wrote map output to ./data/datasets/local/glue_ax_map/./data/datasets/local/glue_ax_map/premise_upper-00000-of-00001.parquet\n",
      "{'premise': 'The cat sat on the mat.', 'premise_upper': 'THE CAT SAT ON THE MAT.'}\n",
      "{'premise': \"When you've got no snow, it's really hard to learn a snow sport so we looked at all the different ways I could mimic being on snow without actually being on snow.\", 'premise_upper': \"WHEN YOU'VE GOT NO SNOW, IT'S REALLY HARD TO LEARN A SNOW SPORT SO WE LOOKED AT ALL THE DIFFERENT WAYS I COULD MIMIC BEING ON SNOW WITHOUT ACTUALLY BEING ON SNOW.\"}\n",
      "{'premise': \"When you've got snow, it's really hard to learn a snow sport so we looked at all the different ways I could mimic being on snow without actually being on snow.\", 'premise_upper': \"WHEN YOU'VE GOT SNOW, IT'S REALLY HARD TO LEARN A SNOW SPORT SO WE LOOKED AT ALL THE DIFFERENT WAYS I COULD MIMIC BEING ON SNOW WITHOUT ACTUALLY BEING ON SNOW.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[local/glue_ax_map][shard 0/1] map \"_upper\" to \"premise_upper\": 100%|██████████| 1104/1104 [00:00<00:00, 51739.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# First, let's just run our map function that upper-cases the 'premise' field without writing a\n",
    "# column to disk until we're happy with the results.\n",
    "def _upper(row: dict, job_id: int) -> str:\n",
    "  return row['premise'].upper()\n",
    "\n",
    "\n",
    "res = glue.map(_upper)\n",
    "print(next(iter(res)))\n",
    "print()\n",
    "\n",
    "# Once we're comfortable with the results, we can write the column to disk.\n",
    "# To do this, we specify `output_column`.\n",
    "glue.map(_upper, output_column='premise_upper', overwrite=True)\n",
    "\n",
    "# Print the first three rows.\n",
    "rows = glue.select_rows(['premise', 'premise_upper'], limit=3)\n",
    "for row in rows:\n",
    "  print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all instances of a keyword and highlight it in the UI\n",
    "\n",
    "We can also use the `nest_under` to nest the result under a specific field.\n",
    "\n",
    "Once a field is nested, we can use `ll.span` to emit the character coordinates, with metadata, of a field we want to highlight from the UI.\n",
    "\n",
    "In this example, we'll simply highlight keywords with \"the\". We'll emit metadata with the span so we can filter by it from the UI!\n",
    "\n",
    "Run the next cell, and then open [this link](http://localhost:5432/datasets#local/glue_ax_map&schemaCollapsed=false&showMetadataPanel=true&expandedStats=%7B%22premise.thes%22%3Atrue%7D&query=%7B%22filters%22%3A%5B%7B%22path%22%3A%5B%22premise%22%2C%22thes%22%5D%2C%22op%22%3A%22equals%22%2C%22value%22%3A%22the%22%7D%5D%7D). You'll notice we had to apply the filter for 'the' before we get highlighting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduling task \"207a165662a04040a58999335bd11bac\": \"[local/glue_ax_map][shard 0/1] map \"_find_the\" to \"thes\"\".\n",
      "Task finished \"dee8d22356a2400aba4210667d937bf7\": \"[local/glue_ax_map][shard 0/1] map \"_upper\" to \"premise_upper\"\" in 4s.\n",
      "Wrote map output to ./data/datasets/local/glue_ax_map/./data/datasets/local/glue_ax_map/premise/thes/thes-00000-of-00001.parquet\n",
      "{'premise': 'The cat sat on the mat.', 'hypothesis': 'The cat did not sit on the mat.', 'label': 'contradiction', 'idx': 0, '__hfsplit__': 'test', 'premise_upper': 'THE CAT SAT ON THE MAT.', 'premise.thes.*': [{'__span__': {'start': 15, 'end': 18}}]}\n",
      "{'premise': \"When you've got no snow, it's really hard to learn a snow sport so we looked at all the different ways I could mimic being on snow without actually being on snow.\", 'hypothesis': \"When you've got snow, it's really hard to learn a snow sport so we looked at all the different ways I could mimic being on snow without actually being on snow.\", 'label': 'contradiction', 'idx': 2, '__hfsplit__': 'test', 'premise_upper': \"WHEN YOU'VE GOT NO SNOW, IT'S REALLY HARD TO LEARN A SNOW SPORT SO WE LOOKED AT ALL THE DIFFERENT WAYS I COULD MIMIC BEING ON SNOW WITHOUT ACTUALLY BEING ON SNOW.\", 'premise.thes.*': [{'__span__': {'start': 84, 'end': 87}}]}\n",
      "{'premise': \"When you've got snow, it's really hard to learn a snow sport so we looked at all the different ways I could mimic being on snow without actually being on snow.\", 'hypothesis': \"When you've got no snow, it's really hard to learn a snow sport so we looked at all the different ways I could mimic being on snow without actually being on snow.\", 'label': 'contradiction', 'idx': 3, '__hfsplit__': 'test', 'premise_upper': \"WHEN YOU'VE GOT SNOW, IT'S REALLY HARD TO LEARN A SNOW SPORT SO WE LOOKED AT ALL THE DIFFERENT WAYS I COULD MIMIC BEING ON SNOW WITHOUT ACTUALLY BEING ON SNOW.\", 'premise.thes.*': [{'__span__': {'start': 81, 'end': 84}}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[local/glue_ax_map][shard 0/1] map \"_find_the\" to \"thes\": 100%|██████████| 1104/1104 [00:00<00:00, 38167.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task finished \"207a165662a04040a58999335bd11bac\": \"[local/glue_ax_map][shard 0/1] map \"_find_the\" to \"thes\"\" in 4s.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Find instances of 'the'.\n",
    "MATCH_REGEX = 'the'\n",
    "\n",
    "\n",
    "def _find_the(item: ll.Item) -> ll.Item:\n",
    "  return [ll.span(m.start(), m.end()) for m in re.finditer(MATCH_REGEX, item['premise'])]\n",
    "\n",
    "\n",
    "glue.map(\n",
    "  _find_the, output_column='thes', nest_under='premise', overwrite=True, combine_columns=False\n",
    ")\n",
    "\n",
    "# Print the first three rows.\n",
    "rows = glue.select_rows([ll.PATH_WILDCARD], combine_columns=False, limit=3)\n",
    "for row in rows:\n",
    "  print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map continuation during an error, or computer shutdown\n",
    "\n",
    "`dataset.map()` will not lose data if an error is thrown when writing to disk.\n",
    "\n",
    "The next time it is called, it will continue from where it left off. Once it is finally complete, the column is written.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduling task \"8720732957904b099176a9f0c7320de1\": \"[local/glue_ax_map][shard 0/1] map \"_upper\" to \"premise_upper2\"\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[local/glue_ax_map][shard 0/1] map \"_upper\" to \"premise_upper2\":  38%|███▊      | 414/1104 [00:00<00:00, 23549.44it/s]\n",
      "2023-11-20 19:13:53,854 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       8720732957904b099176a9f0c7320de1\n",
      "Function:  _execute_task\n",
      "args:      (<function _upper at 0x2a7f7b920>, ('premise_upper2',), './data/.cache/lilac/local/glue_ax_map/premise_upper2.00000-of-00001.jsonl', 0, 1, True, False, False, ('8720732957904b099176a9f0c7320de1', 0))\n",
      "kwargs:    {}\n",
      "Exception: \"ValueError('Throwing for 5c56d63b5f0a401696a8a20ac1f027fa')\"\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Throwing for 5c56d63b5f0a401696a8a20ac1f027fa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/nikhil/Code/lilac/notebooks/DatasetMap.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Code/lilac/notebooks/DatasetMap.ipynb#X60sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m row[\u001b[39m'\u001b[39m\u001b[39mpremise\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mupper()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Code/lilac/notebooks/DatasetMap.ipynb#X60sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# This is going to throw after 10 iterations. When we call it again, it will only call _upper()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Code/lilac/notebooks/DatasetMap.ipynb#X60sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# for the rest of the dataset.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nikhil/Code/lilac/notebooks/DatasetMap.ipynb#X60sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m glue\u001b[39m.\u001b[39;49mmap(_upper, output_column\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpremise_upper2\u001b[39;49m\u001b[39m'\u001b[39;49m, overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, num_jobs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Code/lilac/lilac/data/dataset_duckdb.py:2452\u001b[0m, in \u001b[0;36mDatasetDuckDB.map\u001b[0;34m(self, map_fn, output_column, nest_under, overwrite, combine_columns, resolve_span, num_jobs)\u001b[0m\n\u001b[1;32m   2449\u001b[0m   jsonl_cache_filepaths\u001b[39m.\u001b[39mappend(jsonl_cache_filepath)\n\u001b[1;32m   2451\u001b[0m \u001b[39m# Wait for the tasks to finish before reading the outputs.\u001b[39;00m\n\u001b[0;32m-> 2452\u001b[0m get_task_manager()\u001b[39m.\u001b[39;49mwait(task_ids)\n\u001b[1;32m   2454\u001b[0m reader, map_schema, parquet_filepath \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reshard_cache(\n\u001b[1;32m   2455\u001b[0m   output_path\u001b[39m=\u001b[39moutput_path,\n\u001b[1;32m   2456\u001b[0m   jsonl_cache_filepaths\u001b[39m=\u001b[39mjsonl_cache_filepaths,\n\u001b[1;32m   2457\u001b[0m   is_tmp_output\u001b[39m=\u001b[39mis_tmp_output,\n\u001b[1;32m   2458\u001b[0m )\n\u001b[1;32m   2460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tmp_output:\n",
      "File \u001b[0;32m~/Code/lilac/lilac/tasks.py:203\u001b[0m, in \u001b[0;36mTaskManager.wait\u001b[0;34m(self, task_ids)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m asyncio\u001b[39m.\u001b[39miscoroutine(task_error):\n\u001b[1;32m    202\u001b[0m   task_error \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mget_event_loop()\u001b[39m.\u001b[39mrun_until_complete(task_error)\n\u001b[0;32m--> 203\u001b[0m \u001b[39mraise\u001b[39;00m task_error\n",
      "File \u001b[0;32m~/Code/lilac/.venv/lib/python3.11/site-packages/distributed/worker.py:2983\u001b[0m, in \u001b[0;36mapply_function_simple\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2981\u001b[0m     \u001b[39mwith\u001b[39;00m context_meter\u001b[39m.\u001b[39mmeter(\u001b[39m\"\u001b[39m\u001b[39mthread-noncpu\u001b[39m\u001b[39m\"\u001b[39m, func\u001b[39m=\u001b[39mtime) \u001b[39mas\u001b[39;00m m:\n\u001b[1;32m   2982\u001b[0m         \u001b[39mwith\u001b[39;00m context_meter\u001b[39m.\u001b[39mmeter(\u001b[39m\"\u001b[39m\u001b[39mthread-cpu\u001b[39m\u001b[39m\"\u001b[39m, func\u001b[39m=\u001b[39mthread_time):\n\u001b[0;32m-> 2983\u001b[0m             result \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   2984\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mSystemExit\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m):\n\u001b[1;32m   2985\u001b[0m     \u001b[39m# Special-case these, just like asyncio does all over the place. They will pass\u001b[39;00m\n\u001b[1;32m   2986\u001b[0m     \u001b[39m# through `fail_hard` and `_handle_stimulus_from_task`, and eventually be caught\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2989\u001b[0m     \u001b[39m# Any other `BaseException` types would ultimately be ignored by asyncio if\u001b[39;00m\n\u001b[1;32m   2990\u001b[0m     \u001b[39m# raised here, after messing up the worker state machine along their way.\u001b[39;00m\n\u001b[1;32m   2991\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/lilac/lilac/tasks.py:307\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m annotations \u001b[39m=\u001b[39m cast(\u001b[39mdict\u001b[39m, get_worker()\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mtasks[task_id]\u001b[39m.\u001b[39mannotations)\n\u001b[1;32m    306\u001b[0m annotations[\u001b[39m'\u001b[39m\u001b[39mtask_info\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m task_info\n\u001b[0;32m--> 307\u001b[0m task(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Code/lilac/lilac/data/dataset_duckdb.py:2502\u001b[0m, in \u001b[0;36m_map_worker\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2499\u001b[0m   \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m items:\n\u001b[1;32m   2500\u001b[0m     \u001b[39myield\u001b[39;00m map_fn(item, job_id\u001b[39m=\u001b[39mjob_id)\n\u001b[0;32m-> 2502\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_disk_cached(\n\u001b[1;32m   2503\u001b[0m   _map_iterable,\n\u001b[1;32m   2504\u001b[0m   output_path\u001b[39m=\u001b[39moutput_path,\n\u001b[1;32m   2505\u001b[0m   jsonl_cache_filepath\u001b[39m=\u001b[39mjsonl_cache_filepath,\n\u001b[1;32m   2506\u001b[0m   overwrite\u001b[39m=\u001b[39moverwrite,\n\u001b[1;32m   2507\u001b[0m   combine_columns\u001b[39m=\u001b[39mcombine_columns,\n\u001b[1;32m   2508\u001b[0m   resolve_span\u001b[39m=\u001b[39mresolve_span,\n\u001b[1;32m   2509\u001b[0m   shard_id\u001b[39m=\u001b[39mjob_id,\n\u001b[1;32m   2510\u001b[0m   shard_count\u001b[39m=\u001b[39mjob_count,\n\u001b[1;32m   2511\u001b[0m   task_step_id\u001b[39m=\u001b[39mtask_step_id,\n\u001b[1;32m   2512\u001b[0m   task_step_description\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[shard \u001b[39m\u001b[39m{\u001b[39;00mjob_id\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mjob_count\u001b[39m}\u001b[39;00m\u001b[39m] map \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmap_fn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   2513\u001b[0m )\n",
      "File \u001b[0;32m~/Code/lilac/lilac/data/dataset_duckdb.py:779\u001b[0m, in \u001b[0;36m_compute_disk_cached\u001b[0;34m()\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m   \u001b[39mwith\u001b[39;00m open_file(jsonl_cache_filepath, \u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m--> 779\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m output_items:\n\u001b[1;32m    780\u001b[0m       json\u001b[39m.\u001b[39mdump(item, file)\n\u001b[1;32m    781\u001b[0m       file\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Code/lilac/lilac/tasks.py:363\u001b[0m, in \u001b[0;36mprogress\u001b[0;34m()\u001b[0m\n\u001b[1;32m    361\u001b[0m last_emit \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m emit_every_s\n\u001b[1;32m    362\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(it, initial\u001b[39m=\u001b[39mit_idx, desc\u001b[39m=\u001b[39mtask_info\u001b[39m.\u001b[39mname, total\u001b[39m=\u001b[39mestimated_len) \u001b[39mas\u001b[39;00m tq:\n\u001b[0;32m--> 363\u001b[0m   \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tq:\n\u001b[1;32m    364\u001b[0m     cur_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    365\u001b[0m     \u001b[39mif\u001b[39;00m estimated_len \u001b[39mand\u001b[39;00m cur_time \u001b[39m-\u001b[39m last_emit \u001b[39m>\u001b[39m emit_every_s:\n",
      "File \u001b[0;32m~/Code/lilac/.venv/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36m__iter__\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/lilac/lilac/data/dataset_duckdb.py:760\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    756\u001b[0m   output_items \u001b[39m=\u001b[39m transform_fn(input_values)\n\u001b[1;32m    758\u001b[0m output_items \u001b[39m=\u001b[39m cast(Iterable[Item], wrap_in_dicts(output_items, nested_spec))\n\u001b[0;32m--> 760\u001b[0m output_items \u001b[39m=\u001b[39m (\n\u001b[1;32m    761\u001b[0m   {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mitem, ROWID: rowid} \u001b[39mfor\u001b[39;00m (rowid, _), item \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(inputs_1, output_items) \u001b[39mif\u001b[39;00m item\n\u001b[1;32m    762\u001b[0m )\n\u001b[1;32m    764\u001b[0m \u001b[39m# Add progress.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[39mif\u001b[39;00m task_step_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Code/lilac/lilac/data/dataset_utils.py:96\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_in_dicts\u001b[39m(\u001b[39minput\u001b[39m: Iterable[\u001b[39mobject\u001b[39m], spec: \u001b[39mlist\u001b[39m[PathTuple]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Generator:\n\u001b[1;32m     95\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Wraps an object or iterable in a dict according to the spec.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m   \u001b[39mreturn\u001b[39;00m (_wrap_in_dicts(elem, spec) \u001b[39mfor\u001b[39;00m elem \u001b[39min\u001b[39;00m \u001b[39minput\u001b[39m)\n",
      "File \u001b[0;32m~/Code/lilac/lilac/data/dataset_duckdb.py:2500\u001b[0m, in \u001b[0;36m_map_iterable\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2498\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_map_iterable\u001b[39m(items: Iterable[RichData]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterable[Optional[Item]]:\n\u001b[1;32m   2499\u001b[0m   \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m items:\n\u001b[0;32m-> 2500\u001b[0m     \u001b[39myield\u001b[39;00m map_fn(item, job_id\u001b[39m=\u001b[39mjob_id)\n",
      "\u001b[1;32m/Users/nikhil/Code/lilac/notebooks/DatasetMap.ipynb Cell 8\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nikhil/Code/lilac/notebooks/DatasetMap.ipynb#X60sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mglobal\u001b[39;00m i, throw_after_n\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nikhil/Code/lilac/notebooks/DatasetMap.ipynb#X60sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m throw_for_rowid \u001b[39mand\u001b[39;00m row[ll\u001b[39m.\u001b[39mROWID] \u001b[39m==\u001b[39m random_row_id:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nikhil/Code/lilac/notebooks/DatasetMap.ipynb#X60sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThrowing for \u001b[39m\u001b[39m{\u001b[39;00mrandom_row_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Code/lilac/notebooks/DatasetMap.ipynb#X60sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m row[\u001b[39m'\u001b[39m\u001b[39mpremise\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mupper()\n",
      "\u001b[0;31mValueError\u001b[0m: Throwing for 5c56d63b5f0a401696a8a20ac1f027fa"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task error \"8720732957904b099176a9f0c7320de1\": \"[local/glue_ax_map][shard 0/1] map \"_upper\" to \"premise_upper2\"\" in 0s.\n"
     ]
    }
   ],
   "source": [
    "throw_for_rowid = True\n",
    "\n",
    "random_row_id = list(glue.select_rows([ll.ROWID], limit=1))[0][ll.ROWID]\n",
    "\n",
    "\n",
    "def _upper(item: ll.Item):\n",
    "  global i, throw_after_n\n",
    "  if throw_for_rowid and item[ll.ROWID] == random_row_id:\n",
    "    raise ValueError(f'Throwing for {random_row_id}')\n",
    "  return item['premise'].upper()\n",
    "\n",
    "\n",
    "# This is going to throw after 10 iterations. When we call it again, it will only call _upper()\n",
    "# for the rest of the dataset.\n",
    "glue.map(_upper, output_column='premise_upper2', overwrite=True, num_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduling task \"4130416bb1a5464abebb69d7c6086920\": \"[local/glue_ax_map][shard 0/1] map \"_upper\" to \"premise_upper2\"\".\n",
      "Wrote map output to ./data/datasets/local/glue_ax_map/./data/datasets/local/glue_ax_map/premise_upper2-00000-of-00001.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[local/glue_ax_map][shard 0/1] map \"_upper\" to \"premise_upper2\": 100%|██████████| 1104/1104 [00:00<00:00, 36751.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lilac.data.dataset_duckdb.DuckDBMapOutput at 0x2dbcf2e50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task finished \"4130416bb1a5464abebb69d7c6086920\": \"[local/glue_ax_map][shard 0/1] map \"_upper\" to \"premise_upper2\"\" in 0s.\n"
     ]
    }
   ],
   "source": [
    "throw_for_rowid = False\n",
    "# This will finish calling _upper, without calling it for the first 10 items.\n",
    "glue.map(_upper, output_column='premise_upper2', num_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
